{
  "name": "Spark Streamin",
  "tagline": "Apache Spark Streamin",
  "body": "# Apache Spark\r\n\r\nSpark is a fast and general cluster computing system for Big Data. It provides\r\nhigh-level APIs in Scala, Java, Python, and R, and an optimized engine that\r\nsupports general computation graphs for data analysis. It also supports a\r\nrich set of higher-level tools including Spark SQL for SQL and DataFrames,\r\nMLlib for machine learning, GraphX for graph processing,\r\nand Spark Streaming for stream processing.\r\n\r\n<http://spark.apache.org/>\r\n\r\n\r\n## Online Documentation\r\n\r\nYou can find the latest Spark documentation, including a programming\r\nguide, on the [project web page](http://spark.apache.org/documentation.html)\r\nand [project wiki](https://cwiki.apache.org/confluence/display/SPARK).\r\nThis README file only contains basic setup instructions.\r\n\r\n## Building Spark\r\n\r\nSpark is built using [Apache Maven](http://maven.apache.org/).\r\nTo build Spark and its example programs, run:\r\n\r\n    build/mvn -DskipTests clean package\r\n\r\n(You do not need to do this if you downloaded a pre-built package.)\r\nMore detailed documentation is available from the project site, at\r\n[\"Building Spark\"](http://spark.apache.org/docs/latest/building-spark.html).\r\nFor developing Spark using an IDE, see [Eclipse](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-Eclipse)\r\nand [IntelliJ](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-IntelliJ).\r\n\r\n## Interactive Scala Shell\r\n\r\nThe easiest way to start using Spark is through the Scala shell:\r\n\r\n    ./bin/spark-shell\r\n\r\nTry the following command, which should return 1000:\r\n\r\n    scala> sc.parallelize(1 to 1000).count()\r\n\r\n## Interactive Python Shell\r\n\r\nAlternatively, if you prefer Python, you can use the Python shell:\r\n\r\n    ./bin/pyspark\r\n\r\nAnd run the following command, which should also return 1000:\r\n\r\n    >>> sc.parallelize(range(1000)).count()\r\n\r\n## Example Programs\r\n\r\nSpark also comes with several sample programs in the `examples` directory.\r\nTo run one of them, use `./bin/run-example <class> [params]`. For example:\r\n\r\n    ./bin/run-example SparkPi\r\n\r\nwill run the Pi example locally.\r\n\r\nYou can set the MASTER environment variable when running examples to submit\r\nexamples to a cluster. This can be a mesos:// or spark:// URL,\r\n\"yarn\" to run on YARN, and \"local\" to run\r\nlocally with one thread, or \"local[N]\" to run locally with N threads. You\r\ncan also use an abbreviated class name if the class is in the `examples`\r\npackage. For instance:\r\n\r\n    MASTER=spark://host:7077 ./bin/run-example SparkPi\r\n\r\nMany of the example programs print usage help if no params are given.\r\n\r\n## Running Tests\r\n\r\nTesting first requires [building Spark](#building-spark). Once Spark is built, tests\r\ncan be run using:\r\n\r\n    ./dev/run-tests\r\n\r\nPlease see the guidance on how to\r\n[run tests for a module, or individual tests](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools).\r\n\r\n## A Note About Hadoop Versions\r\n\r\nSpark uses the Hadoop core library to talk to HDFS and other Hadoop-supported\r\nstorage systems. Because the protocols have changed in different versions of\r\nHadoop, you must build Spark against the same version that your cluster runs.\r\n\r\nPlease refer to the build documentation at\r\n[\"Specifying the Hadoop Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)\r\nfor detailed guidance on building for a particular distribution of Hadoop, including\r\nbuilding for particular Hive and Hive Thriftserver distributions.\r\n\r\n## Configuration\r\n\r\nPlease refer to the [Configuration Guide](http://spark.apache.org/docs/latest/configuration.html)\r\nin the online documentation for an overview on how to configure Spark.\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}